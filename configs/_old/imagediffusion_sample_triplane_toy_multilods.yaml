# train setting
train: False
data_dir: ''
latent_dir: ''
schedule_sampler: uniform
lr: 1.0e-4 #5.0e-5
weight_decay: 0.05
microbatch: -1  # -1 disables microbatches
ema_rate: 0.9999  # comma-separated list of EMA values
resume_checkpoint: '' #'/disk2/workspace/Rodin/log/imagediffusion_train/tmax-2023-08-04-02-23-25-912588/model030000.pt'
batch_size: 2 # training batch size
log_interval: 200
save_interval: 20000

# sampling setting 
clip_denoised: True
num_samples: 2 # 10000
batch_size: 2 # sample batch size
use_ddim: False
model_path: '/disk2/workspace/Rodin/log/imagediffusion_train_triplane_toy_multilods/tmax-2023-09-05-04-16-13-187575/model060000.pt'
latent_dir: ''
progress: True

# diffusion default 
learn_sigma: True
sigma_small: False
diffusion_steps: 1000
noise_schedule: 'linear'
timestep_respacing: '1000'
use_kl: False
predict_xstart: False
rescale_timesteps: False
rescale_learned_sigmas: False
guidance_strength: 1.0 # Only for sampling??

# model default
image_size: 256
in_channels: 384
out_channels: 384
latent_dim: 512 #768
model_channels: 256
num_res_blocks: 2
num_heads: 4
num_heads_upsample: -1
num_head_channels: 64
attention_resolutions: '32,16,8'
channel_mult: ''
dropout: 0.1
class_cond: False
use_checkpoint: False
use_scale_shift_norm: True
resblock_updown: True
use_fp16: True
fp16_scale_growth: 1.0e-3
use_new_attention_order: True

# classifier
#anneal_lr: True 
lr_anneal_steps: 0
#iterations: 300000
#classifier_depth: 4
#classifier_width: 128
#classifier_pool: attention
#classifier_resblock_updown: True
#classifier_use_scale_shift_norm: True
#classifier_use_fp16: False
#classifier_attention_resolutions: '32,16,8'
